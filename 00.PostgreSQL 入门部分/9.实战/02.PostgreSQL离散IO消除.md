当我们的一条SQL查询需要返回较多行，或者需要扫描较多行（即使使用索引）时，如果这些行在HEAP表中并非密集存储，而是非常离散的存储，那么扫描的记录数越多，访问的BLOCK就越多，性能会比较差。
我们可以使用cluster的方式让数据按索引的顺序密集存储，减少回表时IO放大

例如:
1、构造实验环境

bill=# create table t_cluster (id int, pos point,crt_time timestamp);
CREATE TABLE
bill=# insert into t_cluster select random()*10000, point(random()*100,random()*100),clock_timestamp() from generate_series(1,10000000);
INSERT 0 10000000
bill=# create index idx_t_cluster on t_cluster using btree(id,crt_time);
CREATE INDEX

2、查询

bill=# explain (analyze ,verbose,timing,costs,buffers) select pos from t_cluster where id = 10 order by crt_time;
                                                               QUERY PLAN                                                               
----------------------------------------------------------------------------------------------------------------------------------------
 Index Scan using idx_t_cluster on public.t_cluster  (cost=0.43..1310.05 rows=996 width=24) (actual time=0.023..1.090 rows=956 loops=1)
   Output: pos, crt_time
   Index Cond: (t_cluster.id = 10)
   Buffers: shared hit=957
 Planning Time: 0.080 ms
 Execution Time: 1.171 ms
(6 rows)

可以看到扫描了957个数据块,返回956行记录

3、对表进行cluster操作
注意:cluster是DDL操作

bill=# cluster t_cluster using idx_t_cluster ;
CLUSTER

4、再进行查询

bill=# explain (analyze ,verbose,timing,costs,buffers) select pos from t_cluster where id = 10 order by crt_time;
                                                               QUERY PLAN                                                               
----------------------------------------------------------------------------------------------------------------------------------------
 Index Scan using idx_t_cluster on public.t_cluster  (cost=0.43..1310.05 rows=996 width=24) (actual time=0.030..0.267 rows=956 loops=1)
   Output: pos, crt_time
   Index Cond: (t_cluster.id = 10)
   Buffers: shared read=15
 Planning Time: 0.239 ms
 Execution Time: 0.342 ms
(6 rows)

可以看到返回同样的记录数,现在只需要扫描15个数据块,时间也从1.171 ms下降到0.342ms,如果在高并发的情况下,性能的提升可想而知

除此之外,PostgreSQL还提供了一种include index的方法也能实现类似的效果,不同于cluster的是我们不需要变更表的结构.
include index是什么原理呢?我们都知道索引扫描的时候如果查询的结果不在索引中是需要回表获取对应的数据,而include index就是利用这点来减少需要扫描的数据块,我们通过将查询的列附加到索引的叶子节点上来实现.即使数据在堆表中存储特别离散,但是include到索引中就不一样了,因为数据在索引中的存储是有序的.

1、构造实验环境

bill=# drop table t_cluster ;
DROP TABLE
bill=# create table t_cluster (id int, pos point,crt_time timestamp);
CREATE TABLE
bill=# insert into t_cluster select random()*10000, point(random()*100,random()*100),clock_timestamp() from generate_series(1,10000000);
INSERT 0 10000000
bill=# create index idx_t_cluster on t_cluster using btree(id,crt_time) include(pos);  
CREATE INDEX
bill=# vacuum (verbose ,analyze) t_cluster ;
psql: INFO:  vacuuming "public.t_cluster"
psql: INFO:  index "idx_t_cluster" now contains 10000000 row versions in 60542 pages
DETAIL:  0 index row versions were removed.
0 index pages have been deleted, 0 are currently reusable.
CPU: user: 0.04 s, system: 0.15 s, elapsed: 0.20 s.
psql: INFO:  "t_cluster": found 0 removable, 10000000 nonremovable row versions in 73530 out of 73530 pages
DETAIL:  0 dead row versions cannot be removed yet, oldest xmin: 34002254
There were 0 unused item identifiers.
Skipped 0 pages due to buffer pins, 0 frozen pages.
0 pages are entirely empty.
CPU: user: 0.67 s, system: 0.21 s, elapsed: 0.89 s.
psql: INFO:  analyzing "public.t_cluster"
psql: INFO:  "t_cluster": scanned 30000 of 73530 pages, containing 4080000 live rows and 0 dead rows; 30000 rows in sample, 10000080 estimated total rows
VACUUM

2、查询

bill=# explain (analyze ,verbose,timing,costs,buffers) select pos from t_cluster where id = 10 order by crt_time;
                                                                QUERY PLAN                                                                 
-------------------------------------------------------------------------------------------------------------------------------------------
 Index Only Scan using idx_t_cluster on public.t_cluster  (cost=0.56..27.12 rows=998 width=24) (actual time=0.030..0.171 rows=972 loops=1)
   Output: pos, crt_time
   Index Cond: (t_cluster.id = 10)
   Heap Fetches: 0
   Buffers: shared hit=13
 Planning Time: 0.080 ms
 Execution Time: 0.247 ms
(7 rows)

可以看到这次只查询了13个数据块,同样的索引我们加上了include就不需要进行回表操作了,性能也大大提升了
目前pg12支持在btree和gist索引上使用 include方法
